import streamlit as st
import pandas as pd
import numpy as np
import joblib
import gdown
import os

# ===== 1. T·∫£i model t·ª´ Google Drive =====
MODEL_FILE = "random_forest_with_encoding.pkl"
MODEL_ID = "1ZerzZ9eLY0twOlbUABwJn2MnYp4DKTHJ"  # ID c·ªßa file tr√™n Google Drive

if not os.path.exists(MODEL_FILE):
    url = f"https://drive.google.com/uc?id={MODEL_ID}"
    gdown.download(url, MODEL_FILE, quiet=False)

# ===== 2. Load model + scaler + encoding_maps =====
loaded_obj = joblib.load(MODEL_FILE)

if not isinstance(loaded_obj, dict):
    st.error("‚ùå File pkl kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng dict ƒë√£ l∆∞u.")
    st.stop()

model = loaded_obj.get("model")
scaler = loaded_obj.get("scaler")
encoding_maps = loaded_obj.get("encoding_maps")
mean_target = loaded_obj.get("mean_target")
cat_cols = loaded_obj.get("cat_cols")

# ===== 3. Load CSV ƒë·ªÉ l·∫•y danh s√°ch gi√° tr·ªã cho dropdown =====
DATA_FILE = "bds_dat_clean.csv"
if not os.path.exists(DATA_FILE):
    st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu '{DATA_FILE}'. H√£y upload file CSV ho·∫∑c ƒë√≠nh k√®m khi deploy.")
    st.stop()

df = pd.read_csv(DATA_FILE)
df.columns = df.columns.str.strip()  # X√≥a kho·∫£ng tr·∫Øng th·ª´a

# ===== 4. Giao di·ªán Streamlit =====
st.title("üîç D·ª± ƒëo√°n gi√° B·∫•t ƒë·ªông s·∫£n")
st.write("Nh·∫≠p th√¥ng tin b·∫•t ƒë·ªông s·∫£n ƒë·ªÉ d·ª± ƒëo√°n:")

# Input d·∫°ng s·ªë
dien_tich = st.number_input("Di·ªán t√≠ch (m¬≤)", min_value=10.0, max_value=2000.0, value=100.0)
mat_tien = st.number_input("M·∫∑t ti·ªÅn (m)", min_value=0.5, max_value=50.0, value=5.0)
duong_vao = st.number_input("ƒê∆∞·ªùng v√†o (m)", min_value=0.5, max_value=50.0, value=3.0)

# Input d·∫°ng ch·ªçn
loai_bds = st.selectbox("Lo·∫°i BƒêS", sorted(df["Lo·∫°i BDS"].dropna().unique()))
giay_to = st.selectbox("Gi·∫•y t·ªù ph√°p l√Ω", sorted(df["Gi·∫•y t·ªù ph√°p l√Ω"].dropna().unique()))
xa_phuong = st.selectbox("X√£/Ph∆∞·ªùng", sorted(df["X√£/Ph∆∞·ªùng"].dropna().unique()))
quan_huyen = st.selectbox("Qu·∫≠n/Huy·ªán", sorted(df["Qu·∫≠n/Huy·ªán"].dropna().unique()))

# ===== 5. X·ª≠ l√Ω khi b·∫•m n√∫t =====
if st.button("D·ª± ƒëo√°n gi√°"):
    try:
        # T·∫°o DataFrame input ban ƒë·∫ßu
        input_df = pd.DataFrame([{
            "Di·ªán t√≠ch (m¬≤)": dien_tich,
            "M·∫∑t ti·ªÅn (m)": mat_tien,
            "ƒê∆∞·ªùng v√†o (m)": duong_vao,
            "Lo·∫°i BDS": loai_bds,
            "Gi·∫•y t·ªù ph√°p l√Ω": giay_to,
            "X√£/Ph∆∞·ªùng": xa_phuong,
            "Qu·∫≠n/Huy·ªán": quan_huyen
        }])

        # ===== Feature engineering =====
        input_df["log_area"] = np.log1p(input_df["Di·ªán t√≠ch (m¬≤)"])
        input_df["frontage_to_road"] = input_df["M·∫∑t ti·ªÅn (m)"] / (input_df["ƒê∆∞·ªùng v√†o (m)"] + 0.1)

        # ===== Target encoding =====
        for col in cat_cols:
            input_df[col + "_te"] = input_df[col].map(encoding_maps[col]).fillna(mean_target)
            input_df.drop(columns=[col], inplace=True)

        # Ch·ªâ gi·ªØ ƒë√∫ng c√°c c·ªôt model c·∫ßn
        final_X = input_df[
            ["Di·ªán t√≠ch (m¬≤)", "M·∫∑t ti·ªÅn (m)", "ƒê∆∞·ªùng v√†o (m)",
             "log_area", "frontage_to_road"] +
            [c + "_te" for c in cat_cols]
        ]

        # ===== Scaling =====
        final_X_scaled = scaler.transform(final_X)

        # ===== D·ª± ƒëo√°n =====
        predicted_price = model.predict(final_X_scaled)[0]
        st.success(f"üí∞ Gi√° d·ª± ƒëo√°n: {predicted_price:,.2f} t·ª∑ VNƒê")

    except Exception as e:
        st.error(f"‚ùå L·ªói khi d·ª± ƒëo√°n: {e}")





# import streamlit as st
# import pandas as pd
# import joblib
# import gdown
# import os
# import numpy as np

# # ===== 1. T·∫£i model t·ª´ Google Drive =====
# MODEL_FILE = "random_forest_with_encoding.pkl"
# MODEL_ID = "1ZerzZ9eLY0twOlbUABwJn2MnYp4DKTHJ"

# if not os.path.exists(MODEL_FILE):
#     url = f"https://drive.google.com/uc?id={MODEL_ID}"
#     gdown.download(url, MODEL_FILE, quiet=False)

# # ===== 2. Load model & encoder =====
# loaded = joblib.load(MODEL_FILE)

# if isinstance(loaded, dict):
#     model = loaded.get("model", loaded)
#     encoders = loaded.get("encoders", {})  # dict ch·ª©a encoder cho t·ª´ng c·ªôt
# else:
#     model = loaded
#     encoders = {}

# # ===== 3. Load CSV ƒë·ªÉ l·∫•y danh s√°ch l·ª±a ch·ªçn =====
# df = pd.read_csv("bds_dat_clean (1).csv")

# # ===== 4. Giao di·ªán Streamlit =====
# st.title("üîç D·ª± ƒëo√°n gi√° B·∫•t ƒë·ªông s·∫£n")

# dien_tich = st.number_input("Di·ªán t√≠ch (m¬≤)", 10.0, 2000.0, 100.0)
# mat_tien = st.number_input("M·∫∑t ti·ªÅn (m)", 0.5, 50.0, 5.0)
# duong_vao = st.number_input("ƒê∆∞·ªùng v√†o (m)", 0.5, 50.0, 3.0)

# loai_bds = st.selectbox("Lo·∫°i BDS", sorted(df["Lo·∫°i BDS"].dropna().unique()))
# giay_to = st.selectbox("Gi·∫•y t·ªù ph√°p l√Ω", sorted(df["Gi·∫•y t·ªù ph√°p l√Ω"].dropna().unique()))
# xa_phuong = st.selectbox("X√£/Ph∆∞·ªùng", sorted(df["X√£/Ph∆∞·ªùng"].dropna().unique()))
# quan_huyen = st.selectbox("Qu·∫≠n/Huy·ªán", sorted(df["Qu·∫≠n/Huy·ªán"].dropna().unique()))

# # ===== 5. X·ª≠ l√Ω khi b·∫•m n√∫t =====
# if st.button("D·ª± ƒëo√°n gi√°"):
#     try:
#         input_df = pd.DataFrame([{
#             "Di·ªán t√≠ch (m¬≤)": dien_tich,
#             "M·∫∑t ti·ªÅn (m)": mat_tien,
#             "ƒê∆∞·ªùng v√†o (m)": duong_vao,
#             "Lo·∫°i BDS": loai_bds,
#             "Gi·∫•y t·ªù ph√°p l√Ω": giay_to,
#             "X√£/Ph∆∞·ªùng": xa_phuong,
#             "Qu·∫≠n/Huy·ªán": quan_huyen
#         }])

#         # Encode d·ªØ li·ªáu n·∫øu c√≥ encoders
#         for col, encoder in encoders.items():
#             if col in input_df.columns:
#                 input_df[col] = encoder.transform(input_df[col])

#         # D·ª± ƒëo√°n
#         pred = model.predict(input_df)[0]
#         st.success(f"üí∞ Gi√° d·ª± ƒëo√°n: {pred:,.2f} t·ª∑ VNƒê")

#     except Exception as e:
#         st.error(f"‚ùå L·ªói: {e}")



# import streamlit as st
# import pandas as pd
# import joblib
# import gdown
# import os
# import numpy as np

# # Th√¥ng tin model tr√™n Drive
# MODEL_FILE = "random_forest_with_encoding.pkl"
# MODEL_ID = "1ZerzZ9eLY0twOlbUABwJn2MnYp4DKTHJ"

# # T·∫£i model t·ª´ Drive n·∫øu ch∆∞a c√≥
# if not os.path.exists(MODEL_FILE):
#     url = f"https://drive.google.com/uc?id={MODEL_ID}"
#     gdown.download(url, MODEL_FILE, quiet=False)

# # Load model (trong dict n·∫øu c·∫ßn)
# loaded = joblib.load(MODEL_FILE)
# if isinstance(loaded, dict) and "model" in loaded:
#     model = loaded["model"]
# else:
#     model = loaded

# # Load CSV ri√™ng t·ª´ repo
# df = pd.read_csv("bds_dat_clean (1).csv")

# st.title("üîç D·ª± ƒëo√°n gi√° B·∫•t ƒë·ªông s·∫£n")

# dien_tich = st.number_input("Di·ªán t√≠ch (m¬≤)", 10.0, 2000.0, 100.0)
# mat_tien = st.number_input("M·∫∑t ti·ªÅn (m)", 0.5, 50.0, 5.0)
# duong_vao = st.number_input("ƒê∆∞·ªùng v√†o (m)", 0.5, 50.0, 3.0)

# loai_bds = st.selectbox("Lo·∫°i BDS", sorted(df["Lo·∫°i BDS"].dropna().unique()))
# giay_to = st.selectbox("Gi·∫•y t·ªù ph√°p l√Ω", sorted(df["Gi·∫•y t·ªù ph√°p l√Ω"].dropna().unique()))
# xa_phuong = st.selectbox("X√£/Ph∆∞·ªùng", sorted(df["X√£/Ph∆∞·ªùng"].dropna().unique()))
# quan_huyen = st.selectbox("Qu·∫≠n/Huy·ªán", sorted(df["Qu·∫≠n/Huy·ªán"].dropna().unique()))

# if st.button("D·ª± ƒëo√°n gi√°"):
#     input_df = pd.DataFrame([{
#         "Di·ªán t√≠ch (m¬≤)": dien_tich,
#         "M·∫∑t ti·ªÅn (m)": mat_tien,
#         "ƒê∆∞·ªùng v√†o (m)": duong_vao,
#         "Lo·∫°i BDS": loai_bds,
#         "Gi·∫•y t·ªù ph√°p l√Ω": giay_to,
#         "X√£/Ph∆∞·ªùng": xa_phuong,
#         "Qu·∫≠n/Huy·ªán": quan_huyen
#     }])
#     try:
#         pred = model.predict(input_df)[0]
#         st.success(f"üí∞ Gi√° d·ª± ƒëo√°n: {pred:,.2f} t·ª∑ VNƒê")
#     except Exception as e:
#         st.error(f"‚ùå L·ªói: {e}")







